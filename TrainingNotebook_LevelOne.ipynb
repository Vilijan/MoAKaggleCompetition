{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:05.698159Z",
     "iopub.status.busy": "2020-12-29T13:41:05.697558Z",
     "iopub.status.idle": "2020-12-29T13:41:16.872360Z",
     "shell.execute_reply": "2020-12-29T13:41:16.871848Z"
    },
    "papermill": {
     "duration": 11.208883,
     "end_time": "2020-12-29T13:41:16.872475",
     "exception": false,
     "start_time": "2020-12-29T13:41:05.663592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "from time import time\n",
    "import datetime\n",
    "from scipy.optimize import minimize, fsolve\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import QuantileTransformer, RobustScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "import torch.nn.functional as F\n",
    "from transformers import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n",
    "\n",
    "import copy\n",
    "\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import sys\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:16.925167Z",
     "iopub.status.busy": "2020-12-29T13:41:16.924653Z",
     "iopub.status.idle": "2020-12-29T13:41:16.931753Z",
     "shell.execute_reply": "2020-12-29T13:41:16.931242Z"
    },
    "papermill": {
     "duration": 0.035918,
     "end_time": "2020-12-29T13:41:16.931839",
     "exception": false,
     "start_time": "2020-12-29T13:41:16.895921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED=42\n",
    "\n",
    "def seed_everything(seed=RANDOM_SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023007,
     "end_time": "2020-12-29T13:41:16.977336",
     "exception": false,
     "start_time": "2020-12-29T13:41:16.954329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:17.031371Z",
     "iopub.status.busy": "2020-12-29T13:41:17.030829Z",
     "iopub.status.idle": "2020-12-29T13:41:24.405218Z",
     "shell.execute_reply": "2020-12-29T13:41:24.404709Z"
    },
    "papermill": {
     "duration": 7.405071,
     "end_time": "2020-12-29T13:41:24.405348",
     "exception": false,
     "start_time": "2020-12-29T13:41:17.000277",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('../input/lish-moa/train_features.csv')\n",
    "test_data = pd.read_csv('../input/lish-moa/test_features.csv')\n",
    "train_drug_ids = pd.read_csv('../input/lish-moa/train_drug.csv') \n",
    "\n",
    "train_targets = pd.read_csv('../input/lish-moa/train_targets_scored.csv')\n",
    "\n",
    "train_data = train_features.merge(train_targets, on='sig_id', how='left')\n",
    "train_data = train_data.merge(train_drug_ids, on='sig_id', how='left') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.457621Z",
     "iopub.status.busy": "2020-12-29T13:41:24.457052Z",
     "iopub.status.idle": "2020-12-29T13:41:24.461173Z",
     "shell.execute_reply": "2020-12-29T13:41:24.460707Z"
    },
    "papermill": {
     "duration": 0.032146,
     "end_time": "2020-12-29T13:41:24.461286",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.429140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_columns = [c for c in train_targets.columns if c != 'sig_id']\n",
    "gene_features = [col for col in train_features.columns if col.startswith('g-')]\n",
    "cell_features = [col for col in train_features.columns if col.startswith('c-')]\n",
    "feature_columns = gene_features + cell_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.025043,
     "end_time": "2020-12-29T13:41:24.509194",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.484151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Cross validation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": false,
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.568651Z",
     "iopub.status.busy": "2020-12-29T13:41:24.567929Z",
     "iopub.status.idle": "2020-12-29T13:41:24.571777Z",
     "shell.execute_reply": "2020-12-29T13:41:24.571300Z"
    },
    "papermill": {
     "duration": 0.039767,
     "end_time": "2020-12-29T13:41:24.571860",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.532093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cross_validation_strategy(data, targets, FOLDS, SEED):\n",
    "\n",
    "    vc = data.drug_id.value_counts()\n",
    "    \n",
    "#     vc1 = vc.loc[(vc==6)|(vc==12)|(vc==18)].index.sort_values()\n",
    "#     vc2 = vc.loc[(vc!=6)&(vc!=12)&(vc!=18)].index.sort_values()\n",
    "    \n",
    "    vc1 = vc.loc[vc <= 19].index.sort_values()\n",
    "    vc2 = vc.loc[vc > 19].index.sort_values()\n",
    "\n",
    "    dct1 = {} \n",
    "    dct2 = {}\n",
    "    skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    tmp = data.groupby('drug_id')[targets].mean().loc[vc1]\n",
    "    \n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.index[idxV].values}\n",
    "        dct1.update(dd)\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    tmp = data.loc[data.drug_id.isin(vc2)].reset_index(drop=True)\n",
    "    \n",
    "    for fold,(idxT,idxV) in enumerate( skf.split(tmp,tmp[targets])):\n",
    "        dd = {k:fold for k in tmp.sig_id[idxV].values}\n",
    "        dct2.update(dd)\n",
    "\n",
    "    # ASSIGN FOLDS\n",
    "    data['fold'] = data.drug_id.map(dct1)\n",
    "    data.loc[data.fold.isna(),'fold'] = data.loc[data.fold.isna(),'sig_id'].map(dct2)\n",
    "    data.fold = data.fold.astype('int8')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023092,
     "end_time": "2020-12-29T13:41:24.649386",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.626294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.715700Z",
     "iopub.status.busy": "2020-12-29T13:41:24.713950Z",
     "iopub.status.idle": "2020-12-29T13:41:24.716361Z",
     "shell.execute_reply": "2020-12-29T13:41:24.716764Z"
    },
    "papermill": {
     "duration": 0.041712,
     "end_time": "2020-12-29T13:41:24.716873",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.675161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoaDataset:\n",
    "    def __init__(self, dataset_df, gene_features, cell_features, target_ids):\n",
    "        self.dataset_df = dataset_df\n",
    "        self.target_ids = target_ids\n",
    "    \n",
    "        self.gene_features = self.dataset_df[gene_features].values\n",
    "        self.cell_features = self.dataset_df[cell_features].values\n",
    "        self.targets = None\n",
    "    \n",
    "        if self.target_ids is not None:\n",
    "            self.targets = self.dataset_df[target_ids].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_df)\n",
    "    \n",
    "    def number_of_features(self):\n",
    "        return self.gene_features.shape[1], self.cell_features.shape[1]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        dataset_sample = {}\n",
    "\n",
    "        dataset_sample['genes'] = torch.tensor(self.gene_features[item, :], dtype=torch.float)\n",
    "        dataset_sample['cells'] = torch.tensor(self.cell_features[item, :], dtype=torch.float)\n",
    "        dataset_sample['sig_id'] = self.dataset_df.loc[item, 'sig_id']\n",
    "\n",
    "        if self.target_ids is not None:\n",
    "            dataset_sample['y'] = torch.tensor(self.targets[item, :], dtype=torch.float)\n",
    "\n",
    "        return dataset_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.768631Z",
     "iopub.status.busy": "2020-12-29T13:41:24.767261Z",
     "iopub.status.idle": "2020-12-29T13:41:24.769621Z",
     "shell.execute_reply": "2020-12-29T13:41:24.770034Z"
    },
    "papermill": {
     "duration": 0.030205,
     "end_time": "2020-12-29T13:41:24.770130",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.739925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelConfig:\n",
    "    def __init__(self, number_of_genes, number_of_cells, number_of_targets):\n",
    "        self.number_of_genes = number_of_genes\n",
    "        self.number_of_cells = number_of_cells\n",
    "        self.number_of_targets = number_of_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.827986Z",
     "iopub.status.busy": "2020-12-29T13:41:24.827404Z",
     "iopub.status.idle": "2020-12-29T13:41:24.830703Z",
     "shell.execute_reply": "2020-12-29T13:41:24.830294Z"
    },
    "papermill": {
     "duration": 0.037574,
     "end_time": "2020-12-29T13:41:24.830788",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.793214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoaModelBlock(nn.Module):\n",
    "    def __init__(self, num_in, num_out, dropout, weight_norm=False, ):\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(num_in)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if weight_norm:\n",
    "            self.linear = nn.utils.weight_norm(nn.Linear(num_in, num_out))\n",
    "        else:\n",
    "            self.linear = nn.Linear(num_in, num_out)\n",
    "        \n",
    "        self.activation = nn.PReLU(num_out)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        x = self.activation(x)\n",
    "        return x\n",
    "\n",
    "class MoaEncodeBlock(nn.Module):\n",
    "    def __init__(self, num_in, num_out, dropout, weight_norm=False):\n",
    "        super().__init__()\n",
    "        self.batch_norm = nn.BatchNorm1d(num_in)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        if weight_norm:\n",
    "            self.linear = nn.utils.weight_norm(nn.Linear(num_in, num_out))\n",
    "        else:\n",
    "            self.linear = nn.Linear(num_in, num_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.886000Z",
     "iopub.status.busy": "2020-12-29T13:41:24.885408Z",
     "iopub.status.idle": "2020-12-29T13:41:24.888224Z",
     "shell.execute_reply": "2020-12-29T13:41:24.888615Z"
    },
    "papermill": {
     "duration": 0.034879,
     "end_time": "2020-12-29T13:41:24.888715",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.853836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoaModel_V1(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        total_features = model_config.number_of_genes + model_config.number_of_cells\n",
    "        dropout = 0.15\n",
    "        hidden_size = 1024\n",
    "        \n",
    "        self.block1 = MoaModelBlock(total_features, 2048, dropout)\n",
    "        self.block2 = MoaModelBlock(2048, 1024, dropout)\n",
    "        self.model = nn.Sequential(\n",
    "                          nn.BatchNorm1d(1024),\n",
    "                          nn.Dropout(dropout),\n",
    "                          nn.Linear(1024, model_config.number_of_targets))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_genes = data['genes']\n",
    "        x_cells = data['cells']\n",
    "        \n",
    "        x = torch.cat((x_genes, x_cells), dim=1)\n",
    "        x = x.to(DEVICE)\n",
    "        \n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:24.946549Z",
     "iopub.status.busy": "2020-12-29T13:41:24.942852Z",
     "iopub.status.idle": "2020-12-29T13:41:24.949075Z",
     "shell.execute_reply": "2020-12-29T13:41:24.948669Z"
    },
    "papermill": {
     "duration": 0.036958,
     "end_time": "2020-12-29T13:41:24.949159",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.912201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoaModel_V2(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        dropout = 0.15\n",
    "        hidden_size = 512\n",
    "        \n",
    "        self.genes_encoder = MoaEncodeBlock(model_config.number_of_genes, 128, dropout)\n",
    "            \n",
    "        self.cells_encoder = MoaEncodeBlock(model_config.number_of_cells, 32, dropout)\n",
    "        \n",
    "        out_encodings = 128 + 32\n",
    "    \n",
    "        self.block1 = MoaModelBlock(128, hidden_size, dropout)\n",
    "        self.block2 = MoaModelBlock(32, hidden_size, dropout)\n",
    "        \n",
    "        self.block3 = MoaModelBlock(hidden_size, hidden_size, dropout)\n",
    "        self.block4 = MoaModelBlock(hidden_size, hidden_size, dropout)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "                          nn.BatchNorm1d(hidden_size),\n",
    "                          nn.Dropout(dropout),\n",
    "                          nn.Linear(hidden_size, model_config.number_of_targets))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_genes = data['genes'].to(DEVICE)\n",
    "        x_cells = data['cells'].to(DEVICE)\n",
    "        \n",
    "        encoded_genes = self.genes_encoder(x_genes)\n",
    "        encoded_cells = self.cells_encoder(x_cells)\n",
    "        \n",
    "        x_genes = self.block1(encoded_genes)\n",
    "        x_cells = self.block2(encoded_cells)\n",
    "\n",
    "        x = self.block3(x_genes + x_cells)\n",
    "        x = self.block4(x)\n",
    "        x = self.model(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.005985Z",
     "iopub.status.busy": "2020-12-29T13:41:25.005403Z",
     "iopub.status.idle": "2020-12-29T13:41:25.008802Z",
     "shell.execute_reply": "2020-12-29T13:41:25.008372Z"
    },
    "papermill": {
     "duration": 0.036256,
     "end_time": "2020-12-29T13:41:25.008881",
     "exception": false,
     "start_time": "2020-12-29T13:41:24.972625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoaModel_V3(nn.Module):\n",
    "    def __init__(self, model_config):\n",
    "        super().__init__()\n",
    "        dropout = 0.15\n",
    "        hidden_size = 512\n",
    "        \n",
    "        self.genes_encoder = MoaEncodeBlock(model_config.number_of_genes, 128, dropout)\n",
    "            \n",
    "        self.cells_encoder = MoaEncodeBlock(model_config.number_of_cells, 32, dropout)\n",
    "            \n",
    "        out_encodings = 128 + 32\n",
    "    \n",
    "        self.block1 = MoaModelBlock(out_encodings, hidden_size, dropout)\n",
    "        self.block2 = MoaModelBlock(hidden_size, hidden_size, dropout)\n",
    "        self.model = nn.Sequential(\n",
    "                          nn.BatchNorm1d(hidden_size),\n",
    "                          nn.Dropout(dropout),\n",
    "                          nn.Linear(hidden_size, model_config.number_of_targets))\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_genes = data['genes'].to(DEVICE)\n",
    "        x_cells = data['cells'].to(DEVICE)\n",
    "        \n",
    "        encoded_genes = self.genes_encoder(x_genes)\n",
    "        encoded_cells = self.cells_encoder(x_cells)\n",
    "               \n",
    "        x = torch.cat((encoded_genes, encoded_cells), 1)\n",
    "        \n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.062528Z",
     "iopub.status.busy": "2020-12-29T13:41:25.061862Z",
     "iopub.status.idle": "2020-12-29T13:41:25.065750Z",
     "shell.execute_reply": "2020-12-29T13:41:25.065325Z"
    },
    "papermill": {
     "duration": 0.033136,
     "end_time": "2020-12-29T13:41:25.065831",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.032695",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class MoaModel_V4(nn.Module):\n",
    "#         def __init__(self, model_config):\n",
    "#             super(MoaModel_V4, self).__init__()\n",
    "            \n",
    "#             num_features = model_config.number_of_genes + model_config.number_of_cells\n",
    "#             hidden_size = 4096\n",
    "            \n",
    "#             cha_1 = 256\n",
    "#             cha_2 = 512\n",
    "#             cha_3 = 512\n",
    "\n",
    "#             cha_1_reshape = int(hidden_size/cha_1)\n",
    "#             cha_po_1 = int(hidden_size/cha_1/2)\n",
    "#             cha_po_2 = int(hidden_size/cha_1/2/2) * cha_3\n",
    "\n",
    "#             self.cha_1 = cha_1\n",
    "#             self.cha_2 = cha_2\n",
    "#             self.cha_3 = cha_3\n",
    "#             self.cha_1_reshape = cha_1_reshape\n",
    "#             self.cha_po_1 = cha_po_1\n",
    "#             self.cha_po_2 = cha_po_2\n",
    "\n",
    "#             self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "#             self.dropout1 = nn.Dropout(0.1)\n",
    "#             self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "\n",
    "#             self.batch_norm_c1 = nn.BatchNorm1d(cha_1)\n",
    "#             self.dropout_c1 = nn.Dropout(0.1)\n",
    "#             self.conv1 = nn.utils.weight_norm(nn.Conv1d(cha_1,cha_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "#             self.ave_po_c1 = nn.AdaptiveAvgPool1d(output_size = cha_po_1)\n",
    "\n",
    "#             self.batch_norm_c2 = nn.BatchNorm1d(cha_2)\n",
    "#             self.dropout_c2 = nn.Dropout(0.1)\n",
    "#             self.conv2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "#             self.batch_norm_c2_1 = nn.BatchNorm1d(cha_2)\n",
    "#             self.dropout_c2_1 = nn.Dropout(0.3)\n",
    "#             self.conv2_1 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "\n",
    "#             self.batch_norm_c2_2 = nn.BatchNorm1d(cha_2)\n",
    "#             self.dropout_c2_2 = nn.Dropout(0.2)\n",
    "#             self.conv2_2 = nn.utils.weight_norm(nn.Conv1d(cha_2,cha_3, kernel_size = 5, stride = 1, padding=2, bias=True),dim=None)\n",
    "\n",
    "#             self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "\n",
    "#             self.flt = nn.Flatten()\n",
    "\n",
    "#             self.batch_norm3 = nn.BatchNorm1d(cha_po_2)\n",
    "#             self.dropout3 = nn.Dropout(0.2)\n",
    "#             self.dense3 = nn.utils.weight_norm(nn.Linear(cha_po_2, model_config.number_of_targets))\n",
    "\n",
    "#         def forward(self, data):\n",
    "            \n",
    "#             x_genes = data['genes']\n",
    "#             x_cells = data['cells']\n",
    "\n",
    "#             x = torch.cat((x_genes, x_cells), dim=1)\n",
    "#             x = x.to(DEVICE)\n",
    "\n",
    "#             x = self.batch_norm1(x)\n",
    "#             x = self.dropout1(x)\n",
    "#             x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "#             x = x.reshape(x.shape[0],self.cha_1,\n",
    "#                           self.cha_1_reshape)\n",
    "\n",
    "#             x = self.batch_norm_c1(x)\n",
    "#             x = self.dropout_c1(x)\n",
    "#             x = F.relu(self.conv1(x))\n",
    "\n",
    "#             x = self.ave_po_c1(x)\n",
    "\n",
    "#             x = self.batch_norm_c2(x)\n",
    "#             x = self.dropout_c2(x)\n",
    "#             x = F.relu(self.conv2(x))\n",
    "#             x_s = x\n",
    "\n",
    "#             x = self.batch_norm_c2_1(x)\n",
    "#             x = self.dropout_c2_1(x)\n",
    "#             x = F.relu(self.conv2_1(x))\n",
    "\n",
    "#             x = self.batch_norm_c2_2(x)\n",
    "#             x = self.dropout_c2_2(x)\n",
    "#             x = F.relu(self.conv2_2(x))\n",
    "#             x =  x * x_s\n",
    "\n",
    "#             x = self.max_po_c2(x)\n",
    "\n",
    "#             x = self.flt(x)\n",
    "\n",
    "#             x = self.batch_norm3(x)\n",
    "#             x = self.dropout3(x)\n",
    "#             x = self.dense3(x)\n",
    "\n",
    "#             return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.136241Z",
     "iopub.status.busy": "2020-12-29T13:41:25.121556Z",
     "iopub.status.idle": "2020-12-29T13:41:25.139629Z",
     "shell.execute_reply": "2020-12-29T13:41:25.139171Z"
    },
    "papermill": {
     "duration": 0.049851,
     "end_time": "2020-12-29T13:41:25.139713",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.089862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvFeatureExtractions(nn.Module):\n",
    "    def __init__(self, num_features, hidden_size, channel_1=256, channel_2=512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.channel_1 = channel_1\n",
    "        self.channel_2 = channel_2\n",
    "        self.final_conv_features = int(hidden_size / channel_1) * channel_2\n",
    "            \n",
    "        self.batch_norm1 = nn.BatchNorm1d(num_features)\n",
    "        self.dropout1 = nn.Dropout(0.15)\n",
    "        self.dense1 = nn.utils.weight_norm(nn.Linear(num_features, hidden_size))\n",
    "               \n",
    "        self.batch_norm_c1 = nn.BatchNorm1d(channel_1)\n",
    "        self.dropout_c1 = nn.Dropout(0.15)\n",
    "        self.conv1 = nn.utils.weight_norm(nn.Conv1d(channel_1,channel_2, kernel_size = 5, stride = 1, padding=2,  bias=False),dim=None)\n",
    "\n",
    "        self.batch_norm_c2 = nn.BatchNorm1d(channel_2)\n",
    "        self.dropout_c2 = nn.Dropout(0.2)\n",
    "        self.conv2 = nn.utils.weight_norm(nn.Conv1d(channel_2,channel_2, kernel_size = 3, stride = 1, padding=1, bias=True),dim=None)\n",
    "        \n",
    "        self.max_po_c2 = nn.MaxPool1d(kernel_size=4, stride=2, padding=1)\n",
    "        self.final_conv_features = int(self.final_conv_features / 2)\n",
    "        \n",
    "        self.flt = nn.Flatten()\n",
    "     \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = F.celu(self.dense1(x), alpha=0.06)\n",
    "\n",
    "        x = x.reshape(x.shape[0], self.channel_1, -1)\n",
    "        \n",
    "        x = self.batch_norm_c1(x)\n",
    "        x = self.dropout_c1(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "\n",
    "        x = self.batch_norm_c2(x)\n",
    "        x = self.dropout_c2(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        \n",
    "        x = self.max_po_c2(x)\n",
    "        \n",
    "        x = self.flt(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "\n",
    "\n",
    "class MoaModel_V4(nn.Module):\n",
    "        def __init__(self, model_config):\n",
    "            super(MoaModel_V4, self).__init__()\n",
    "            hidden_size = 512\n",
    "            dropout = 0.15\n",
    "            \n",
    "            self.gene_cnn_features = ConvFeatureExtractions(model_config.number_of_genes, 2048, channel_1=128, channel_2=256)\n",
    "            self.cell_cnn_features = ConvFeatureExtractions(model_config.number_of_cells, 1024, channel_1=64, channel_2=128)\n",
    "            \n",
    "            encoded_features = self.gene_cnn_features.final_conv_features + self.cell_cnn_features.final_conv_features\n",
    "            \n",
    "            self.block1 = MoaModelBlock(encoded_features, hidden_size, dropout, weight_norm=True)\n",
    "            self.model = MoaEncodeBlock(hidden_size, model_config.number_of_targets, dropout, weight_norm=True)\n",
    "            \n",
    "\n",
    "        def forward(self, data):\n",
    "            \n",
    "            x_genes = data['genes'].to(DEVICE)\n",
    "            x_cells = data['cells'].to(DEVICE)\n",
    "\n",
    "            x_genes = self.gene_cnn_features(x_genes)\n",
    "            x_cells = self.cell_cnn_features(x_cells)\n",
    "            \n",
    "            x = torch.cat((x_genes, x_cells), dim=1)\n",
    "\n",
    "            x = self.block1(x)\n",
    "            x = self.model(x)\n",
    "\n",
    "            return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024031,
     "end_time": "2020-12-29T13:41:25.188243",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.164212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Smooth loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.253057Z",
     "iopub.status.busy": "2020-12-29T13:41:25.251860Z",
     "iopub.status.idle": "2020-12-29T13:41:25.254751Z",
     "shell.execute_reply": "2020-12-29T13:41:25.254355Z"
    },
    "papermill": {
     "duration": 0.042797,
     "end_time": "2020-12-29T13:41:25.254834",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.212037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SmoothCrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight=None, reduction='mean', smoothing=0.0):\n",
    "        super().__init__(weight=weight, reduction=reduction)\n",
    "        self.smoothing = smoothing\n",
    "        self.weight = weight\n",
    "        self.reduction = reduction\n",
    "\n",
    "    @staticmethod\n",
    "    def _smooth(targets, n_classes, smoothing=0.0):\n",
    "        assert 0 <= smoothing <= 1\n",
    "        with torch.no_grad():\n",
    "            targets = targets * (1 - smoothing) + torch.ones_like(targets).to(DEVICE) * smoothing / n_classes\n",
    "        return targets\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        targets = SmoothCrossEntropyLoss()._smooth(targets, inputs.shape[1], self.smoothing)\n",
    "\n",
    "        if self.weight is not None:\n",
    "            inputs = inputs * self.weight.unsqueeze(0)\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(inputs, targets)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "class SmoothBCEwLogits(_WeightedLoss):\n",
    "        def __init__(self, weight=None, reduction='mean', smoothing=0.0,pos_weight = None):\n",
    "            super().__init__(weight=weight, reduction=reduction)\n",
    "            self.smoothing = smoothing\n",
    "            self.weight = weight\n",
    "            self.reduction = reduction\n",
    "            self.pos_weight = pos_weight\n",
    "\n",
    "        @staticmethod\n",
    "        def _smooth(targets:torch.Tensor, n_labels:int, smoothing=0.0):\n",
    "            assert 0 <= smoothing < 1\n",
    "            with torch.no_grad():\n",
    "                targets = targets * (1.0 - smoothing) + 0.5 * smoothing\n",
    "            return targets\n",
    "\n",
    "        def forward(self, inputs, targets):\n",
    "            targets = SmoothBCEwLogits._smooth(targets, inputs.size(-1),\n",
    "                self.smoothing)\n",
    "            loss = F.binary_cross_entropy_with_logits(inputs, targets,self.weight,\n",
    "                                                      pos_weight = self.pos_weight)\n",
    "\n",
    "            if  self.reduction == 'sum':\n",
    "                loss = loss.sum()\n",
    "            elif  self.reduction == 'mean':\n",
    "                loss = loss.mean()\n",
    "\n",
    "            return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023703,
     "end_time": "2020-12-29T13:41:25.302831",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.279128",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Scaling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.379355Z",
     "iopub.status.busy": "2020-12-29T13:41:25.358814Z",
     "iopub.status.idle": "2020-12-29T13:41:25.381869Z",
     "shell.execute_reply": "2020-12-29T13:41:25.381444Z"
    },
    "papermill": {
     "duration": 0.055051,
     "end_time": "2020-12-29T13:41:25.381959",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.326908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def true_rank_gaus_scale(data, columns): \n",
    "    global DEVICE\n",
    "    \n",
    "    if DEVICE == 'cuda':\n",
    "        import cupy as cp\n",
    "        from cupyx.scipy.special import erfinv\n",
    "        epsilon = 1e-6\n",
    "\n",
    "        for f in columns:\n",
    "            r_gpu = cp.array(data[f].values)\n",
    "            r_gpu = r_gpu.argsort().argsort()\n",
    "            r_gpu = (r_gpu/r_gpu.max()-0.5)*2 \n",
    "            r_gpu = cp.clip(r_gpu,-1+epsilon,1-epsilon)\n",
    "            r_gpu = erfinv(r_gpu) \n",
    "            data[f] = cp.asnumpy( r_gpu * np.sqrt(2) )\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    from scipy.special import erfinv as sp_erfinv\n",
    "    \n",
    "    epsilon = 1e-6\n",
    "    \n",
    "    for f in columns:\n",
    "        r_cpu = data[f].values.argsort().argsort()\n",
    "        r_cpu = (r_cpu/r_cpu.max()-0.5)*2 \n",
    "        r_cpu = np.clip(r_cpu,-1+epsilon,1-epsilon)\n",
    "        r_cpu = sp_erfinv(r_cpu) \n",
    "        data[f] = r_cpu * np.sqrt(2)\n",
    "        \n",
    "    return data\n",
    "\n",
    "#THIS IS NOT CORRECT SINCE IT NEEDS TO BE SCALED ONLY BY TRAIN DATA\n",
    "# def quantile_scale_dosetime(data, columns):\n",
    "#     global RANDOM_SEED\n",
    "#     arr = []\n",
    "    \n",
    "#     for cp_dose in ['D1', 'D2']:\n",
    "#         for cp_time in [24, 48, 72]:\n",
    "#             temp_data = data[data.cp_dose == cp_dose].reset_index(drop=True)\n",
    "#             temp_data = temp_data[temp_data.cp_time == cp_time].reset_index(drop=True)\n",
    "\n",
    "#             scaler = QuantileTransformer(n_quantiles=100,random_state=RANDOM_SEED, output_distribution=\"normal\")\n",
    "#             temp_data[columns] = scaler.fit_transform(temp_data[columns])\n",
    "#             arr.append(temp_data)\n",
    "            \n",
    "#     return pd.concat(arr).reset_index(drop=True)\n",
    "\n",
    "def quantile_dosetime_scaling(train_data, valid_data, test_data, feature_columns):\n",
    "    global RANDOM_SEED\n",
    "    \n",
    "    train_arr = []\n",
    "    valid_arr = []\n",
    "    test_arr = []\n",
    "    \n",
    "    for cp_dose in ['D1', 'D2']:\n",
    "        for cp_time in [24, 48, 72]:\n",
    "            temp_train = train_data[train_data.cp_dose == cp_dose].reset_index(drop=True)\n",
    "            temp_train = temp_train[temp_train.cp_time == cp_time].reset_index(drop=True)\n",
    "            \n",
    "            temp_valid = valid_data[valid_data.cp_dose == cp_dose].reset_index(drop=True)\n",
    "            temp_valid = temp_valid[temp_valid.cp_time == cp_time].reset_index(drop=True)\n",
    "            \n",
    "            temp_test = test_data[test_data.cp_dose == cp_dose].reset_index(drop=True)\n",
    "            temp_test = temp_test[temp_test.cp_time == cp_time].reset_index(drop=True)\n",
    "\n",
    "            scaler = QuantileTransformer(n_quantiles=100,random_state=RANDOM_SEED, output_distribution=\"normal\")\n",
    "            temp_train[feature_columns] = scaler.fit_transform(temp_train[feature_columns])\n",
    "            temp_valid[feature_columns] = scaler.transform(temp_valid[feature_columns])\n",
    "            temp_test[feature_columns] = scaler.transform(temp_test[feature_columns])\n",
    "            \n",
    "            train_arr.append(temp_train)\n",
    "            valid_arr.append(temp_valid)\n",
    "            test_arr.append(temp_test)\n",
    "            \n",
    "    train_data = pd.concat(train_arr).reset_index(drop=True)\n",
    "    valid_data = pd.concat(valid_arr).reset_index(drop=True)\n",
    "    test_data = pd.concat(test_arr).reset_index(drop=True)\n",
    "            \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "def true_rankgaus_dosetime(data, columns):\n",
    "    global RANDOM_SEED\n",
    "    arr = []\n",
    "    \n",
    "    for cp_dose in ['D1', 'D2']:\n",
    "        for cp_time in [24, 48, 72]:\n",
    "            temp_data = data[data.cp_dose == cp_dose].reset_index(drop=True)\n",
    "            temp_data = temp_data[temp_data.cp_time == cp_time].reset_index(drop=True)\n",
    "            \n",
    "            arr.append(true_rank_gaus_scale(temp_data, columns))\n",
    "        \n",
    "    return pd.concat(arr).reset_index(drop=True)\n",
    "\n",
    "def true_rankgaus_dosetime_scaling(train_data, valid_data, test_data, feature_columns):\n",
    "    \n",
    "    train_data = true_rankgaus_dosetime(train_data, feature_columns)\n",
    "    valid_data = true_rankgaus_dosetime(valid_data, feature_columns)\n",
    "    test_data = true_rankgaus_dosetime(test_data, feature_columns)\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "    \n",
    "\n",
    "def true_rankgaus_scaling(train_data, valid_data, test_data, feature_columns):\n",
    "    \n",
    "    train_data = true_rank_gaus_scale(train_data, feature_columns)\n",
    "    valid_data = true_rank_gaus_scale(valid_data, feature_columns)\n",
    "    test_data = true_rank_gaus_scale(test_data, feature_columns)\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "    \n",
    "\n",
    "def quantile_scaling(train_data, valid_data, test_data, feature_columns):\n",
    "    global RANDOM_SEED\n",
    "    \n",
    "    scaler = QuantileTransformer(n_quantiles=100,random_state=RANDOM_SEED, output_distribution=\"normal\")\n",
    "    train_data[feature_columns] = scaler.fit_transform(train_data[feature_columns])\n",
    "    valid_data[feature_columns] = scaler.transform(valid_data[feature_columns])\n",
    "    test_data[feature_columns] = scaler.transform(test_data[feature_columns])\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "#THIS SHOULD NOT BE CORRECT\n",
    "# def quantile_dosetime_scaling(train_data, valid_data, test_data):\n",
    "    \n",
    "#     global feature_columns\n",
    "    \n",
    "#     train_data = quantile_scale_dosetime(train_data, feature_columns)\n",
    "#     valid_data = quantile_scale_dosetime(valid_data, feature_columns)\n",
    "#     test_data = quantile_scale_dosetime(test_data, feature_columns)\n",
    "    \n",
    "#     return train_data, valid_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024375,
     "end_time": "2020-12-29T13:41:25.430520",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.406145",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.486800Z",
     "iopub.status.busy": "2020-12-29T13:41:25.485040Z",
     "iopub.status.idle": "2020-12-29T13:41:25.487432Z",
     "shell.execute_reply": "2020-12-29T13:41:25.487835Z"
    },
    "papermill": {
     "duration": 0.032707,
     "end_time": "2020-12-29T13:41:25.487943",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.455236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_dataloader(data, batch_size, shuffle, target_columns=None):\n",
    "    gene_features = [c for c in data.columns if 'g-' in c]\n",
    "    cell_features = [c for c in data.columns if 'c-' in c]\n",
    "    \n",
    "    dataset = MoaDataset(data, gene_features, cell_features, target_columns)\n",
    "    \n",
    "    return torch.utils.data.DataLoader(dataset,\n",
    "                                       batch_size=batch_size,\n",
    "                                       shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.551603Z",
     "iopub.status.busy": "2020-12-29T13:41:25.550880Z",
     "iopub.status.idle": "2020-12-29T13:41:25.554279Z",
     "shell.execute_reply": "2020-12-29T13:41:25.554672Z"
    },
    "papermill": {
     "duration": 0.042646,
     "end_time": "2020-12-29T13:41:25.554776",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.512130",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pca_transform(fitted_pca, data, feature_columns, sig_ids, base_feature_name):\n",
    "    feature_data = fitted_pca.transform(data[feature_columns].values)\n",
    "    df = pd.DataFrame(feature_data, columns =[f'{base_feature_name}-{i}' for i in range(feature_data.shape[1])])\n",
    "    df['sig_id'] = sig_ids\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_fold_data(train_data, test_data, fold, scaling_func=None, add_pca=False):\n",
    "    global feature_columns, target_columns, gene_features, cell_features\n",
    "    \n",
    "    fold_train_data = train_data[train_data.fold != fold].reset_index(drop=True)\n",
    "    fold_valid_data = train_data[train_data.fold == fold].reset_index(drop=True)\n",
    "    \n",
    "    if add_pca:\n",
    "        fold_data = [fold_train_data, fold_valid_data, test_data]\n",
    "        \n",
    "        pca_genes = PCA(n_components=150)\n",
    "        pca_cells = PCA(n_components=30)\n",
    "        \n",
    "        pca_genes.fit(fold_train_data[gene_features].values)\n",
    "        pca_cells.fit(fold_train_data[cell_features].values)\n",
    "        \n",
    "        for fitted_pca, pca_features, colum_name in [(pca_genes, gene_features, 'g-pca'), (pca_cells, cell_features, 'c-pca')]:\n",
    "            for i, pca_data in enumerate(fold_data):\n",
    "                fitted_pca_data = pca_transform(fitted_pca=fitted_pca, \n",
    "                                                data=pca_data, \n",
    "                                                feature_columns=pca_features, \n",
    "                                                sig_ids=pca_data.sig_id.values, \n",
    "                                                base_feature_name=colum_name)\n",
    "                fold_data[i] = pd.merge(fold_data[i], fitted_pca_data, on='sig_id')\n",
    "            \n",
    "           \n",
    "        fold_train_data = fold_data[0]\n",
    "        fold_valid_data = fold_data[1]\n",
    "        test_data = fold_data[2]\n",
    "    \n",
    "    if scaling_func is not None:\n",
    "        fold_train_data, fold_valid_data, test_data = scaling_func(fold_train_data, fold_valid_data, test_data, feature_columns)\n",
    "      \n",
    "    train_dataloader = create_dataloader(data=fold_train_data, batch_size=BATCH_SIZE, shuffle=True, target_columns=target_columns)\n",
    "    valid_dataloader = create_dataloader(data=fold_valid_data, batch_size=BATCH_SIZE, shuffle=False, target_columns=target_columns)\n",
    "    test_dataloader = create_dataloader(data=test_data, batch_size=BATCH_SIZE, shuffle=False, target_columns=None)\n",
    "    \n",
    "    return train_dataloader, valid_dataloader, test_dataloader     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024618,
     "end_time": "2020-12-29T13:41:25.603738",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.579120",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Blending functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.674667Z",
     "iopub.status.busy": "2020-12-29T13:41:25.672855Z",
     "iopub.status.idle": "2020-12-29T13:41:25.675312Z",
     "shell.execute_reply": "2020-12-29T13:41:25.675729Z"
    },
    "papermill": {
     "duration": 0.047806,
     "end_time": "2020-12-29T13:41:25.675829",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.628023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def log_loss_numpy(y_pred):\n",
    "    loss = 0\n",
    "    y_pred_clip = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    for i in range(y_pred.shape[1]):\n",
    "        loss += - np.mean(y_true[:, i] * np.log(y_pred_clip[:, i]) + (1 - y_true[:, i]) * np.log(1 - y_pred_clip[:, i]))\n",
    "    return loss / y_pred.shape[1]\n",
    "\n",
    "def func_numpy_metric(weights):\n",
    "    oof_blend = np.tensordot(weights, oof, axes = ((0), (0)))\n",
    "    score = log_loss_numpy(oof_blend)\n",
    "    \n",
    "    coef = 1e-6\n",
    "    penalty = coef * (np.sum(weights) - 1) ** 2\n",
    "    return score + penalty\n",
    "\n",
    "def grad_func(weights):\n",
    "    oof_clip = np.clip(oof, 1e-15, 1 - 1e-15)\n",
    "    gradients = np.zeros(oof.shape[0])\n",
    "    for i in range(oof.shape[0]):\n",
    "        a, b, c = y_true, oof_clip[i], 0\n",
    "        for j in range(oof.shape[0]):\n",
    "            if j != i:\n",
    "                c += weights[j] * oof_clip[j]\n",
    "        gradients[i] = -np.mean((-a*b+(b**2)*weights[i]+b*c)/((b**2)*(weights[i]**2)+2*b*c*weights[i]-b*weights[i]+(c**2)-c))\n",
    "    return gradients\n",
    "\n",
    "oof = []\n",
    "y_true = []\n",
    "def find_optimal_blend(predictions, train_data, target_columns):\n",
    "    \n",
    "    global oof, y_true\n",
    "    y_true = train_data.sort_values(by='sig_id')[target_columns].values\n",
    "    oof = np.zeros((len(predictions), y_true.shape[0], y_true.shape[1]))\n",
    "\n",
    "    for i, pred in enumerate(predictions):\n",
    "        oof[i] = pred.sort_values(by='sig_id')[target_columns].values\n",
    "\n",
    "    tol = 1e-10\n",
    "    init_guess = [1 / oof.shape[0]] * oof.shape[0]\n",
    "    bnds = [(0, 1) for _ in range(oof.shape[0])]\n",
    "    cons = {'type': 'eq', \n",
    "            'fun': lambda x: np.sum(x) - 1, \n",
    "            'jac': lambda x: [1] * len(x)}\n",
    "\n",
    "    res_scipy = minimize(fun = func_numpy_metric, \n",
    "                         x0 = init_guess, \n",
    "                         method = 'SLSQP', \n",
    "                         jac = grad_func, \n",
    "                         bounds = bnds, \n",
    "                         constraints = cons, \n",
    "                         tol = tol)\n",
    "    \n",
    "    return res_scipy.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024845,
     "end_time": "2020-12-29T13:41:25.725685",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.700840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.781069Z",
     "iopub.status.busy": "2020-12-29T13:41:25.780518Z",
     "iopub.status.idle": "2020-12-29T13:41:25.783654Z",
     "shell.execute_reply": "2020-12-29T13:41:25.783238Z"
    },
    "papermill": {
     "duration": 0.033697,
     "end_time": "2020-12-29T13:41:25.783739",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.750042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def inference(model, data_loader, target_columns):\n",
    "    predictions = []\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for batch in data_loader:\n",
    "        batch_predictions = model(batch).sigmoid().detach().cpu().numpy()\n",
    "        sig_ids = np.array(batch['sig_id'])\n",
    "\n",
    "        df = pd.DataFrame(batch_predictions, columns=target_columns)\n",
    "        df['sig_id'] = sig_ids\n",
    "        predictions.append(df)\n",
    "\n",
    "    return pd.concat(predictions).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.848536Z",
     "iopub.status.busy": "2020-12-29T13:41:25.846842Z",
     "iopub.status.idle": "2020-12-29T13:41:25.849188Z",
     "shell.execute_reply": "2020-12-29T13:41:25.849610Z"
    },
    "papermill": {
     "duration": 0.041192,
     "end_time": "2020-12-29T13:41:25.849709",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.808517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_log_loss(predicted_df, train_df, target_columns):\n",
    "    predicted_df = predicted_df.copy()\n",
    "    train_df = train_df.copy()\n",
    "    \n",
    "    predicted_df = predicted_df[target_columns + ['sig_id']].reset_index(drop=True)\n",
    "    predicted_df = predicted_df.sort_values(by=['sig_id'])\n",
    "    predicted_df = predicted_df.drop('sig_id', axis=1)\n",
    "\n",
    "    true_df = train_df[target_columns + ['sig_id']].reset_index(drop=True)\n",
    "    true_df = true_df.sort_values(by=['sig_id'])\n",
    "    true_df = true_df.drop('sig_id', axis=1)\n",
    "\n",
    "    predicted_values = predicted_df.values\n",
    "    true_values = true_df.values\n",
    "    \n",
    "    score = 0\n",
    "    loss_per_class = []\n",
    "    for i in range(predicted_values.shape[1]):\n",
    "        _score = log_loss(true_values[:, i].astype(np.float), predicted_values[:, i].astype(np.float), eps=1e-15, labels=[1,0])\n",
    "        loss_per_class.append(_score)\n",
    "        score += _score / predicted_values.shape[1]\n",
    "\n",
    "    return score, loss_per_class\n",
    "\n",
    "def scale_predictions(predictions, target_columns, scale_values=None):\n",
    "    predictions = [p.copy() for p in predictions]\n",
    "    predictions = [p.sort_values(by=['sig_id']).reset_index(drop=True) for p in predictions]\n",
    "    \n",
    "    final_predictions = np.zeros((predictions[0].shape[0], len(target_columns)))\n",
    "    \n",
    "    for i, p in enumerate(predictions):\n",
    "        p_values = p[target_columns].values\n",
    "        \n",
    "        if scale_values is None:\n",
    "            final_predictions += p_values / len(predictions)\n",
    "        else:\n",
    "            final_predictions += (p_values * scale_values[i])\n",
    "        \n",
    "    predictions_df = predictions[0].copy()\n",
    "    predictions_df.loc[:, target_columns] = final_predictions\n",
    "    \n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.918906Z",
     "iopub.status.busy": "2020-12-29T13:41:25.917488Z",
     "iopub.status.idle": "2020-12-29T13:41:25.920009Z",
     "shell.execute_reply": "2020-12-29T13:41:25.920440Z"
    },
    "papermill": {
     "duration": 0.045546,
     "end_time": "2020-12-29T13:41:25.920539",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.874993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainFactory:\n",
    "    \n",
    "    @classmethod\n",
    "    def model_version1(cls, train_loader, epochs):\n",
    "        global model_config, DEVICE\n",
    "        \n",
    "        model = MoaModel_V1(model_config).to(DEVICE)\n",
    "        best_model = MoaModel_V1(model_config).to(DEVICE)\n",
    "        \n",
    "#         optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "#                                      lr=1e-3,\n",
    "#                                      weight_decay=3e-5)\n",
    "        \n",
    "#         scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "#                                                         max_lr=5e-2,\n",
    "#                                                         epochs=epochs, \n",
    "#                                                         steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.04647353847564317, weight_decay=8.087569236449597e-06)\n",
    "\n",
    "        scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=len(train_loader)*epochs//2, num_training_steps=len(train_loader)*epochs)\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        return model, best_model, optimizer, scheduler, loss_fn\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def model_version2(cls, train_loader, epochs):\n",
    "        global model_config, DEVICE\n",
    "        \n",
    "        model = MoaModel_V2(model_config).to(DEVICE)\n",
    "        best_model = MoaModel_V2(model_config).to(DEVICE)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                     lr=1e-3,\n",
    "                                     weight_decay=1e-5)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                                        max_lr=1e-2,\n",
    "                                                        epochs=epochs, \n",
    "                                                        steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        return model, best_model, optimizer, scheduler, loss_fn\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def model_version3(cls, train_loader, epochs):\n",
    "        global model_config, DEVICE\n",
    "        \n",
    "        model = MoaModel_V3(model_config).to(DEVICE)\n",
    "        best_model = MoaModel_V3(model_config).to(DEVICE)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                     lr=1e-3,\n",
    "                                     weight_decay=1e-5)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                                        max_lr=1e-2,\n",
    "                                                        epochs=epochs, \n",
    "                                                        steps_per_epoch=len(train_loader))\n",
    "\n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "        return model, best_model, optimizer, scheduler, loss_fn\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def model_version4(cls, train_loader, epochs):\n",
    "        global model_config, DEVICE\n",
    "        \n",
    "        model = MoaModel_V4(model_config).to(DEVICE)\n",
    "        best_model = MoaModel_V4(model_config).to(DEVICE)\n",
    "        \n",
    "        optimizer = torch.optim.Adam(params=model.parameters(),\n",
    "                                     lr=1e-3,\n",
    "                                     weight_decay=1e-5)\n",
    "        \n",
    "        scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer,\n",
    "                                                        max_lr=5e-3,\n",
    "                                                        epochs=epochs, \n",
    "                                                        steps_per_epoch=len(train_loader))\n",
    "\n",
    "#         optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "#         scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer=optimizer, pct_start=0.1, div_factor=1e3, \n",
    "#                                                   max_lr=1e-2, epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "        \n",
    "        loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "        return model, best_model, optimizer, scheduler, loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:25.982298Z",
     "iopub.status.busy": "2020-12-29T13:41:25.980962Z",
     "iopub.status.idle": "2020-12-29T13:41:25.983375Z",
     "shell.execute_reply": "2020-12-29T13:41:25.983783Z"
    },
    "papermill": {
     "duration": 0.038655,
     "end_time": "2020-12-29T13:41:25.983879",
     "exception": false,
     "start_time": "2020-12-29T13:41:25.945224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, best_model, optimizer, scheduler, loss_fn, train_loader, valid_loader, test_loader, epochs):\n",
    "    global gene_features, cell_features, target_columns\n",
    "    \n",
    "    train_data = train_loader.dataset.dataset_df\n",
    "    valid_data = valid_loader.dataset.dataset_df\n",
    "    \n",
    "    best_loss = np.inf\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for train_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = model(train_batch)\n",
    "            y_true = train_batch['y'].to(DEVICE)\n",
    "            \n",
    "            curr_train_loss = loss_fn(y_pred, y_true)\n",
    "            \n",
    "            curr_train_loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            train_loss += ( curr_train_loss.item() * (len(train_batch['sig_id']) / len(train_data)))\n",
    "            \n",
    "            \n",
    "        valid_predictions = inference(model, valid_loader, target_columns)\n",
    "        valid_loss, _ = calculate_log_loss(valid_predictions, valid_data, target_columns)\n",
    "        \n",
    "        if valid_loss < best_loss:\n",
    "            best_loss = valid_loss\n",
    "            best_model.load_state_dict(model.state_dict())\n",
    "            \n",
    "                           \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch:{epoch} \\t train_loss:{train_loss:.10f} \\t valid_loss:{valid_loss:.10f}')\n",
    "            \n",
    "    \n",
    "    valid_predictions = inference(best_model, valid_loader, target_columns)\n",
    "    test_predictions = inference(best_model, test_loader, target_columns)\n",
    "    \n",
    "    return best_model, valid_predictions, test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:26.039723Z",
     "iopub.status.busy": "2020-12-29T13:41:26.039040Z",
     "iopub.status.idle": "2020-12-29T13:41:26.042648Z",
     "shell.execute_reply": "2020-12-29T13:41:26.042208Z"
    },
    "papermill": {
     "duration": 0.033888,
     "end_time": "2020-12-29T13:41:26.042738",
     "exception": false,
     "start_time": "2020-12-29T13:41:26.008850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "FOLDS = 5\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 128\n",
    "SEEDS = [11, 221, 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:26.107553Z",
     "iopub.status.busy": "2020-12-29T13:41:26.099931Z",
     "iopub.status.idle": "2020-12-29T13:41:26.817867Z",
     "shell.execute_reply": "2020-12-29T13:41:26.817040Z"
    },
    "papermill": {
     "duration": 0.74686,
     "end_time": "2020-12-29T13:41:26.817976",
     "exception": false,
     "start_time": "2020-12-29T13:41:26.071116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=42 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py:70: FutureWarning: Pass shuffle=True, random_state=42 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Creating the cross validation strategy\n",
    "train_data = create_cross_validation_strategy(train_data, target_columns, FOLDS, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:26.879191Z",
     "iopub.status.busy": "2020-12-29T13:41:26.878217Z",
     "iopub.status.idle": "2020-12-29T13:41:27.024448Z",
     "shell.execute_reply": "2020-12-29T13:41:27.023698Z"
    },
    "papermill": {
     "duration": 0.180181,
     "end_time": "2020-12-29T13:41:27.024556",
     "exception": false,
     "start_time": "2020-12-29T13:41:26.844375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data = train_data[train_data.cp_type == 'trt_cp'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:27.084116Z",
     "iopub.status.busy": "2020-12-29T13:41:27.082567Z",
     "iopub.status.idle": "2020-12-29T13:41:27.084815Z",
     "shell.execute_reply": "2020-12-29T13:41:27.085217Z"
    },
    "papermill": {
     "duration": 0.034118,
     "end_time": "2020-12-29T13:41:27.085354",
     "exception": false,
     "start_time": "2020-12-29T13:41:27.051236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelTrainConfig:\n",
    "    def __init__(self, model_name, factory_func, scaling_func, add_pca):\n",
    "        self.model_name = model_name\n",
    "        self.factory_func = factory_func\n",
    "        self.scaling_func = scaling_func\n",
    "        self.add_pca = add_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:27.147174Z",
     "iopub.status.busy": "2020-12-29T13:41:27.145464Z",
     "iopub.status.idle": "2020-12-29T13:41:27.147795Z",
     "shell.execute_reply": "2020-12-29T13:41:27.148191Z"
    },
    "papermill": {
     "duration": 0.036184,
     "end_time": "2020-12-29T13:41:27.148307",
     "exception": false,
     "start_time": "2020-12-29T13:41:27.112123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_version1 = ModelTrainConfig(model_name='version_1', \n",
    "                                  factory_func=TrainFactory.model_version1, \n",
    "                                  scaling_func=true_rankgaus_scaling,\n",
    "                                  add_pca=False)\n",
    "\n",
    "model_version2 = ModelTrainConfig(model_name='version_2', \n",
    "                                  factory_func=TrainFactory.model_version2, \n",
    "                                  scaling_func=quantile_dosetime_scaling,\n",
    "                                  add_pca=False)\n",
    "\n",
    "model_version3 = ModelTrainConfig(model_name='version_3', \n",
    "                                  factory_func=TrainFactory.model_version3, \n",
    "                                  scaling_func=quantile_scaling,\n",
    "                                  add_pca=False)\n",
    "\n",
    "model_version4 = ModelTrainConfig(model_name='version_4', \n",
    "                                  factory_func=TrainFactory.model_version4, \n",
    "                                  scaling_func=quantile_scaling,\n",
    "                                  add_pca=False)\n",
    "\n",
    "models_train_configs = [model_version1, model_version2, model_version3, model_version4]\n",
    "#models_train_configs = [model_version4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T13:41:27.214801Z",
     "iopub.status.busy": "2020-12-29T13:41:27.213952Z",
     "iopub.status.idle": "2020-12-29T15:21:46.726049Z",
     "shell.execute_reply": "2020-12-29T15:21:46.726866Z"
    },
    "papermill": {
     "duration": 6019.552426,
     "end_time": "2020-12-29T15:21:46.727018",
     "exception": false,
     "start_time": "2020-12-29T13:41:27.174592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model:version_1\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0186646465 \t valid_loss:0.0187850279\n",
      "Epoch:9 \t train_loss:0.0189539609 \t valid_loss:0.0195378892\n",
      "Epoch:14 \t train_loss:0.0204105963 \t valid_loss:0.0203869686\n",
      "Epoch:19 \t train_loss:0.0201283952 \t valid_loss:0.0195157384\n",
      "Epoch:24 \t train_loss:0.0186819164 \t valid_loss:0.0183624131\n",
      "Epoch:29 \t train_loss:0.0161599823 \t valid_loss:0.0170575871\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0247784558 \t valid_loss:0.0207367345\n",
      "Epoch:9 \t train_loss:0.0187313250 \t valid_loss:0.0193012083\n",
      "Epoch:14 \t train_loss:0.0199654153 \t valid_loss:0.0205130168\n",
      "Epoch:19 \t train_loss:0.0198497827 \t valid_loss:0.0205473328\n",
      "Epoch:24 \t train_loss:0.0183039755 \t valid_loss:0.0186049616\n",
      "Epoch:29 \t train_loss:0.0156739520 \t valid_loss:0.0174691290\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0189323321 \t valid_loss:0.0207827511\n",
      "Epoch:9 \t train_loss:0.0187724986 \t valid_loss:0.0196357454\n",
      "Epoch:14 \t train_loss:0.0200782873 \t valid_loss:0.0215078611\n",
      "Epoch:19 \t train_loss:0.0199515160 \t valid_loss:0.0203294667\n",
      "Epoch:24 \t train_loss:0.0184750886 \t valid_loss:0.0182934239\n",
      "Epoch:29 \t train_loss:0.0157589026 \t valid_loss:0.0174492286\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0186134335 \t valid_loss:0.0192081143\n",
      "Epoch:9 \t train_loss:0.0192463627 \t valid_loss:0.0204897273\n",
      "Epoch:14 \t train_loss:0.0202420322 \t valid_loss:0.0210379609\n",
      "Epoch:19 \t train_loss:0.0202728722 \t valid_loss:0.0208771841\n",
      "Epoch:24 \t train_loss:0.0186747832 \t valid_loss:0.0183167381\n",
      "Epoch:29 \t train_loss:0.0162678936 \t valid_loss:0.0170856367\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0202882241 \t valid_loss:0.0192712729\n",
      "Epoch:9 \t train_loss:0.0188438694 \t valid_loss:0.0189967278\n",
      "Epoch:14 \t train_loss:0.0199936994 \t valid_loss:0.0202049490\n",
      "Epoch:19 \t train_loss:0.0199757117 \t valid_loss:0.0197504606\n",
      "Epoch:24 \t train_loss:0.0183851249 \t valid_loss:0.0182920861\n",
      "Epoch:29 \t train_loss:0.0158216852 \t valid_loss:0.0171877437\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_1 \t Seed:11 \t oof_loss:0.0172470141\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0210051428 \t valid_loss:0.0191412614\n",
      "Epoch:9 \t train_loss:0.0191183777 \t valid_loss:0.0191578759\n",
      "Epoch:14 \t train_loss:0.0202725580 \t valid_loss:0.0221070278\n",
      "Epoch:19 \t train_loss:0.0200906798 \t valid_loss:0.0195983633\n",
      "Epoch:24 \t train_loss:0.0185363200 \t valid_loss:0.0182973743\n",
      "Epoch:29 \t train_loss:0.0159554388 \t valid_loss:0.0171128088\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0183617050 \t valid_loss:0.0190616003\n",
      "Epoch:9 \t train_loss:0.0188906399 \t valid_loss:0.0199456224\n",
      "Epoch:14 \t train_loss:0.0199664263 \t valid_loss:0.0201428079\n",
      "Epoch:19 \t train_loss:0.0201104276 \t valid_loss:0.0202765539\n",
      "Epoch:24 \t train_loss:0.0185304594 \t valid_loss:0.0185433380\n",
      "Epoch:29 \t train_loss:0.0159619096 \t valid_loss:0.0175295403\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0203734052 \t valid_loss:0.0248381003\n",
      "Epoch:9 \t train_loss:0.0188394710 \t valid_loss:0.0210172189\n",
      "Epoch:14 \t train_loss:0.0200424813 \t valid_loss:0.0209019612\n",
      "Epoch:19 \t train_loss:0.0201116358 \t valid_loss:0.0198893038\n",
      "Epoch:24 \t train_loss:0.0186690184 \t valid_loss:0.0184562232\n",
      "Epoch:29 \t train_loss:0.0158894557 \t valid_loss:0.0174420150\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0193224743 \t valid_loss:0.0189647596\n",
      "Epoch:9 \t train_loss:0.0189930529 \t valid_loss:0.0193173921\n",
      "Epoch:14 \t train_loss:0.0202014712 \t valid_loss:0.0279423653\n",
      "Epoch:19 \t train_loss:0.0200808793 \t valid_loss:0.0201397015\n",
      "Epoch:24 \t train_loss:0.0186574950 \t valid_loss:0.0182427066\n",
      "Epoch:29 \t train_loss:0.0161752167 \t valid_loss:0.0170802188\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0192700527 \t valid_loss:0.0189598787\n",
      "Epoch:9 \t train_loss:0.0189310240 \t valid_loss:0.0200311407\n",
      "Epoch:14 \t train_loss:0.0200828799 \t valid_loss:0.0202192395\n",
      "Epoch:19 \t train_loss:0.0200718444 \t valid_loss:0.0203745874\n",
      "Epoch:24 \t train_loss:0.0185296246 \t valid_loss:0.0183296292\n",
      "Epoch:29 \t train_loss:0.0160411894 \t valid_loss:0.0171909271\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_1 \t Seed:221 \t oof_loss:0.0172696376\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0192118205 \t valid_loss:0.0189648989\n",
      "Epoch:9 \t train_loss:0.0189749190 \t valid_loss:0.0190705872\n",
      "Epoch:14 \t train_loss:0.0202110025 \t valid_loss:0.0217110045\n",
      "Epoch:19 \t train_loss:0.0200525082 \t valid_loss:0.0201021058\n",
      "Epoch:24 \t train_loss:0.0186451644 \t valid_loss:0.0180855222\n",
      "Epoch:29 \t train_loss:0.0160645701 \t valid_loss:0.0170665180\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0222807388 \t valid_loss:0.0200915128\n",
      "Epoch:9 \t train_loss:0.0188889709 \t valid_loss:0.0196803820\n",
      "Epoch:14 \t train_loss:0.0196654974 \t valid_loss:0.0207793814\n",
      "Epoch:19 \t train_loss:0.0195544865 \t valid_loss:0.0199336323\n",
      "Epoch:24 \t train_loss:0.0181146317 \t valid_loss:0.0185320123\n",
      "Epoch:29 \t train_loss:0.0154742062 \t valid_loss:0.0174443337\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0214053086 \t valid_loss:0.0195418686\n",
      "Epoch:9 \t train_loss:0.0188581865 \t valid_loss:0.0198931988\n",
      "Epoch:14 \t train_loss:0.0198676085 \t valid_loss:0.0204498081\n",
      "Epoch:19 \t train_loss:0.0198934459 \t valid_loss:0.0202331434\n",
      "Epoch:24 \t train_loss:0.0183071242 \t valid_loss:0.0184080024\n",
      "Epoch:29 \t train_loss:0.0155835312 \t valid_loss:0.0174481789\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0214705418 \t valid_loss:0.0226689142\n",
      "Epoch:9 \t train_loss:0.0195907390 \t valid_loss:0.0200893724\n",
      "Epoch:14 \t train_loss:0.0195706963 \t valid_loss:0.0198915591\n",
      "Epoch:19 \t train_loss:0.0195670989 \t valid_loss:0.0201864749\n",
      "Epoch:24 \t train_loss:0.0180334879 \t valid_loss:0.0180473934\n",
      "Epoch:29 \t train_loss:0.0153968124 \t valid_loss:0.0170258514\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0189942736 \t valid_loss:0.0186785841\n",
      "Epoch:9 \t train_loss:0.0189109076 \t valid_loss:0.0191688152\n",
      "Epoch:14 \t train_loss:0.0202516688 \t valid_loss:0.0198320951\n",
      "Epoch:19 \t train_loss:0.0202148026 \t valid_loss:0.0194950776\n",
      "Epoch:24 \t train_loss:0.0185641569 \t valid_loss:0.0183795396\n",
      "Epoch:29 \t train_loss:0.0160488333 \t valid_loss:0.0172029909\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_1 \t Seed:50 \t oof_loss:0.0172261048\n",
      "Model:version_1 \t valid_loss:0.0171078454\n",
      "Training model:version_2\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0182967814 \t valid_loss:0.0180499071\n",
      "Epoch:9 \t train_loss:0.0178271437 \t valid_loss:0.0183092837\n",
      "Epoch:14 \t train_loss:0.0176536075 \t valid_loss:0.0181576422\n",
      "Epoch:19 \t train_loss:0.0173069077 \t valid_loss:0.0176790458\n",
      "Epoch:24 \t train_loss:0.0161647473 \t valid_loss:0.0172159093\n",
      "Epoch:29 \t train_loss:0.0150067020 \t valid_loss:0.0170149018\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0185947992 \t valid_loss:0.0192555324\n",
      "Epoch:9 \t train_loss:0.0177312383 \t valid_loss:0.0185325311\n",
      "Epoch:14 \t train_loss:0.0177063555 \t valid_loss:0.0185186382\n",
      "Epoch:19 \t train_loss:0.0172555343 \t valid_loss:0.0180647403\n",
      "Epoch:24 \t train_loss:0.0161524276 \t valid_loss:0.0177759448\n",
      "Epoch:29 \t train_loss:0.0151066288 \t valid_loss:0.0174587855\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0186224624 \t valid_loss:0.0195261870\n",
      "Epoch:9 \t train_loss:0.0180983414 \t valid_loss:0.0183905546\n",
      "Epoch:14 \t train_loss:0.0177565942 \t valid_loss:0.0184969514\n",
      "Epoch:19 \t train_loss:0.0171922410 \t valid_loss:0.0179032698\n",
      "Epoch:24 \t train_loss:0.0160891057 \t valid_loss:0.0176122271\n",
      "Epoch:29 \t train_loss:0.0150348937 \t valid_loss:0.0174300642\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0187387279 \t valid_loss:0.0181606806\n",
      "Epoch:9 \t train_loss:0.0199700601 \t valid_loss:0.0196251924\n",
      "Epoch:14 \t train_loss:0.0186213532 \t valid_loss:0.0185244549\n",
      "Epoch:19 \t train_loss:0.0179260578 \t valid_loss:0.0178683044\n",
      "Epoch:24 \t train_loss:0.0170544976 \t valid_loss:0.0175190220\n",
      "Epoch:29 \t train_loss:0.0163430359 \t valid_loss:0.0171875283\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0186865092 \t valid_loss:0.0181488792\n",
      "Epoch:9 \t train_loss:0.0179042553 \t valid_loss:0.0178327846\n",
      "Epoch:14 \t train_loss:0.0177463842 \t valid_loss:0.0182142874\n",
      "Epoch:19 \t train_loss:0.0172364728 \t valid_loss:0.0177633684\n",
      "Epoch:24 \t train_loss:0.0161515105 \t valid_loss:0.0172493730\n",
      "Epoch:29 \t train_loss:0.0149985420 \t valid_loss:0.0170529550\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_2 \t Seed:11 \t oof_loss:0.0172131784\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0184832415 \t valid_loss:0.0179375659\n",
      "Epoch:9 \t train_loss:0.0178255030 \t valid_loss:0.0181352209\n",
      "Epoch:14 \t train_loss:0.0177377196 \t valid_loss:0.0179394535\n",
      "Epoch:19 \t train_loss:0.0173274655 \t valid_loss:0.0176074233\n",
      "Epoch:24 \t train_loss:0.0161865147 \t valid_loss:0.0173398346\n",
      "Epoch:29 \t train_loss:0.0150659720 \t valid_loss:0.0169705637\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0185719242 \t valid_loss:0.0186540566\n",
      "Epoch:9 \t train_loss:0.0177056380 \t valid_loss:0.0184083521\n",
      "Epoch:14 \t train_loss:0.0174510024 \t valid_loss:0.0183424335\n",
      "Epoch:19 \t train_loss:0.0171846741 \t valid_loss:0.0182504658\n",
      "Epoch:24 \t train_loss:0.0160376881 \t valid_loss:0.0175795189\n",
      "Epoch:29 \t train_loss:0.0149070562 \t valid_loss:0.0174593743\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0184286888 \t valid_loss:0.0194828235\n",
      "Epoch:9 \t train_loss:0.0189847926 \t valid_loss:0.0185896496\n",
      "Epoch:14 \t train_loss:0.0178882372 \t valid_loss:0.0187505759\n",
      "Epoch:19 \t train_loss:0.0173421863 \t valid_loss:0.0181171945\n",
      "Epoch:24 \t train_loss:0.0163054708 \t valid_loss:0.0177450345\n",
      "Epoch:29 \t train_loss:0.0152545143 \t valid_loss:0.0175025346\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0188021839 \t valid_loss:0.0182658859\n",
      "Epoch:9 \t train_loss:0.0180237851 \t valid_loss:0.0184793760\n",
      "Epoch:14 \t train_loss:0.0179689078 \t valid_loss:0.0183523460\n",
      "Epoch:19 \t train_loss:0.0175068362 \t valid_loss:0.0179615584\n",
      "Epoch:24 \t train_loss:0.0162854045 \t valid_loss:0.0172658367\n",
      "Epoch:29 \t train_loss:0.0152736445 \t valid_loss:0.0170368773\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0184577857 \t valid_loss:0.0196752114\n",
      "Epoch:9 \t train_loss:0.0177256665 \t valid_loss:0.0179535925\n",
      "Epoch:14 \t train_loss:0.0176344819 \t valid_loss:0.0181128076\n",
      "Epoch:19 \t train_loss:0.0171498914 \t valid_loss:0.0176004754\n",
      "Epoch:24 \t train_loss:0.0159855061 \t valid_loss:0.0171438108\n",
      "Epoch:29 \t train_loss:0.0148432337 \t valid_loss:0.0171002337\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_2 \t Seed:221 \t oof_loss:0.0172033214\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0187569140 \t valid_loss:0.0181774068\n",
      "Epoch:9 \t train_loss:0.0182872054 \t valid_loss:0.0181622144\n",
      "Epoch:14 \t train_loss:0.0178788668 \t valid_loss:0.0182039869\n",
      "Epoch:19 \t train_loss:0.0174267098 \t valid_loss:0.0181673825\n",
      "Epoch:24 \t train_loss:0.0162797268 \t valid_loss:0.0171590379\n",
      "Epoch:29 \t train_loss:0.0152113072 \t valid_loss:0.0170293189\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0183428110 \t valid_loss:0.0187563702\n",
      "Epoch:9 \t train_loss:0.0179515968 \t valid_loss:0.0185437179\n",
      "Epoch:14 \t train_loss:0.0176854405 \t valid_loss:0.0185237160\n",
      "Epoch:19 \t train_loss:0.0171795649 \t valid_loss:0.0181200609\n",
      "Epoch:24 \t train_loss:0.0161738879 \t valid_loss:0.0176234808\n",
      "Epoch:29 \t train_loss:0.0150271219 \t valid_loss:0.0174571415\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0194670515 \t valid_loss:0.0183472958\n",
      "Epoch:9 \t train_loss:0.0178128485 \t valid_loss:0.0185732493\n",
      "Epoch:14 \t train_loss:0.0176852660 \t valid_loss:0.0184295501\n",
      "Epoch:19 \t train_loss:0.0172411629 \t valid_loss:0.0179752769\n",
      "Epoch:24 \t train_loss:0.0160477276 \t valid_loss:0.0175897346\n",
      "Epoch:29 \t train_loss:0.0150007761 \t valid_loss:0.0174256738\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0188392341 \t valid_loss:0.0217064831\n",
      "Epoch:9 \t train_loss:0.0197756420 \t valid_loss:0.0188114078\n",
      "Epoch:14 \t train_loss:0.0180350142 \t valid_loss:0.0185114244\n",
      "Epoch:19 \t train_loss:0.0175192353 \t valid_loss:0.0178488184\n",
      "Epoch:24 \t train_loss:0.0164306589 \t valid_loss:0.0172278017\n",
      "Epoch:29 \t train_loss:0.0154139132 \t valid_loss:0.0170023803\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0186627077 \t valid_loss:0.0182651353\n",
      "Epoch:9 \t train_loss:0.0182223169 \t valid_loss:0.0180200948\n",
      "Epoch:14 \t train_loss:0.0178303662 \t valid_loss:0.0180290143\n",
      "Epoch:19 \t train_loss:0.0172040241 \t valid_loss:0.0178178864\n",
      "Epoch:24 \t train_loss:0.0161497483 \t valid_loss:0.0173302396\n",
      "Epoch:29 \t train_loss:0.0150867483 \t valid_loss:0.0170728301\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_2 \t Seed:50 \t oof_loss:0.0171891465\n",
      "Model:version_2 \t valid_loss:0.0170618974\n",
      "Training model:version_3\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0185236066 \t valid_loss:0.0178336136\n",
      "Epoch:9 \t train_loss:0.0185149570 \t valid_loss:0.0185064466\n",
      "Epoch:14 \t train_loss:0.0172174823 \t valid_loss:0.0176110932\n",
      "Epoch:19 \t train_loss:0.0166099903 \t valid_loss:0.0174924230\n",
      "Epoch:24 \t train_loss:0.0154594390 \t valid_loss:0.0172152180\n",
      "Epoch:29 \t train_loss:0.0141246336 \t valid_loss:0.0171497810\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0192928138 \t valid_loss:0.0187941250\n",
      "Epoch:9 \t train_loss:0.0170880543 \t valid_loss:0.0184146442\n",
      "Epoch:14 \t train_loss:0.0169754424 \t valid_loss:0.0183247313\n",
      "Epoch:19 \t train_loss:0.0163462526 \t valid_loss:0.0183864692\n",
      "Epoch:24 \t train_loss:0.0150642740 \t valid_loss:0.0177052445\n",
      "Epoch:29 \t train_loss:0.0136835858 \t valid_loss:0.0177488920\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0186725329 \t valid_loss:0.0188314641\n",
      "Epoch:9 \t train_loss:0.0185306197 \t valid_loss:0.0185297616\n",
      "Epoch:14 \t train_loss:0.0175752640 \t valid_loss:0.0180732912\n",
      "Epoch:19 \t train_loss:0.0168341671 \t valid_loss:0.0179567986\n",
      "Epoch:24 \t train_loss:0.0157231818 \t valid_loss:0.0175846776\n",
      "Epoch:29 \t train_loss:0.0146460422 \t valid_loss:0.0175146275\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0189973040 \t valid_loss:0.0180487841\n",
      "Epoch:9 \t train_loss:0.0177483665 \t valid_loss:0.0186931469\n",
      "Epoch:14 \t train_loss:0.0173632630 \t valid_loss:0.0179258275\n",
      "Epoch:19 \t train_loss:0.0168730938 \t valid_loss:0.0174869904\n",
      "Epoch:24 \t train_loss:0.0155776312 \t valid_loss:0.0172602219\n",
      "Epoch:29 \t train_loss:0.0144854647 \t valid_loss:0.0171211392\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0182481357 \t valid_loss:0.0179151101\n",
      "Epoch:9 \t train_loss:0.0174117640 \t valid_loss:0.0179764742\n",
      "Epoch:14 \t train_loss:0.0170409883 \t valid_loss:0.0181231169\n",
      "Epoch:19 \t train_loss:0.0165061713 \t valid_loss:0.0177042046\n",
      "Epoch:24 \t train_loss:0.0150795324 \t valid_loss:0.0172686732\n",
      "Epoch:29 \t train_loss:0.0136629484 \t valid_loss:0.0172606907\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_3 \t Seed:11 \t oof_loss:0.0173302843\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0181965043 \t valid_loss:0.0181023336\n",
      "Epoch:9 \t train_loss:0.0174363170 \t valid_loss:0.0179141893\n",
      "Epoch:14 \t train_loss:0.0171192674 \t valid_loss:0.0178504093\n",
      "Epoch:19 \t train_loss:0.0165600857 \t valid_loss:0.0175272923\n",
      "Epoch:24 \t train_loss:0.0153193179 \t valid_loss:0.0173799506\n",
      "Epoch:29 \t train_loss:0.0138584248 \t valid_loss:0.0172216856\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0183547751 \t valid_loss:0.0185167310\n",
      "Epoch:9 \t train_loss:0.0202133493 \t valid_loss:0.0201241254\n",
      "Epoch:14 \t train_loss:0.0182349218 \t valid_loss:0.0189101662\n",
      "Epoch:19 \t train_loss:0.0173913770 \t valid_loss:0.0184116199\n",
      "Epoch:24 \t train_loss:0.0163648846 \t valid_loss:0.0177620874\n",
      "Epoch:29 \t train_loss:0.0155196888 \t valid_loss:0.0176006421\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0182474872 \t valid_loss:0.0184151277\n",
      "Epoch:9 \t train_loss:0.0178053331 \t valid_loss:0.0207021960\n",
      "Epoch:14 \t train_loss:0.0172285205 \t valid_loss:0.0182546669\n",
      "Epoch:19 \t train_loss:0.0166803876 \t valid_loss:0.0181655970\n",
      "Epoch:24 \t train_loss:0.0154512291 \t valid_loss:0.0177122586\n",
      "Epoch:29 \t train_loss:0.0142426057 \t valid_loss:0.0175904363\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0185479077 \t valid_loss:0.0189057875\n",
      "Epoch:9 \t train_loss:0.0183566535 \t valid_loss:0.0181830623\n",
      "Epoch:14 \t train_loss:0.0175701343 \t valid_loss:0.0177543625\n",
      "Epoch:19 \t train_loss:0.0169150691 \t valid_loss:0.0177038997\n",
      "Epoch:24 \t train_loss:0.0158547915 \t valid_loss:0.0172558932\n",
      "Epoch:29 \t train_loss:0.0145437271 \t valid_loss:0.0171111970\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0183689575 \t valid_loss:0.0183581359\n",
      "Epoch:9 \t train_loss:0.0173725839 \t valid_loss:0.0179764738\n",
      "Epoch:14 \t train_loss:0.0171345128 \t valid_loss:0.0177270659\n",
      "Epoch:19 \t train_loss:0.0165421929 \t valid_loss:0.0177044716\n",
      "Epoch:24 \t train_loss:0.0152283456 \t valid_loss:0.0172391794\n",
      "Epoch:29 \t train_loss:0.0138625205 \t valid_loss:0.0172109091\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_3 \t Seed:221 \t oof_loss:0.0173199846\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0183878645 \t valid_loss:0.0181501754\n",
      "Epoch:9 \t train_loss:0.0173323441 \t valid_loss:0.0178727797\n",
      "Epoch:14 \t train_loss:0.0170958481 \t valid_loss:0.0179430839\n",
      "Epoch:19 \t train_loss:0.0165214344 \t valid_loss:0.0176712258\n",
      "Epoch:24 \t train_loss:0.0151958577 \t valid_loss:0.0172647254\n",
      "Epoch:29 \t train_loss:0.0137513626 \t valid_loss:0.0172355467\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0183842315 \t valid_loss:0.0184201317\n",
      "Epoch:9 \t train_loss:0.0183404468 \t valid_loss:0.0184065469\n",
      "Epoch:14 \t train_loss:0.0171163772 \t valid_loss:0.0184252351\n",
      "Epoch:19 \t train_loss:0.0166032484 \t valid_loss:0.0180646444\n",
      "Epoch:24 \t train_loss:0.0152689443 \t valid_loss:0.0177934174\n",
      "Epoch:29 \t train_loss:0.0139372754 \t valid_loss:0.0176887946\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0185230293 \t valid_loss:0.0194369462\n",
      "Epoch:9 \t train_loss:0.0174416509 \t valid_loss:0.0186079191\n",
      "Epoch:14 \t train_loss:0.0172019072 \t valid_loss:0.0181337665\n",
      "Epoch:19 \t train_loss:0.0166127711 \t valid_loss:0.0179646653\n",
      "Epoch:24 \t train_loss:0.0154861549 \t valid_loss:0.0176446503\n",
      "Epoch:29 \t train_loss:0.0141836401 \t valid_loss:0.0175287047\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0186221089 \t valid_loss:0.0195279559\n",
      "Epoch:9 \t train_loss:0.0189038373 \t valid_loss:0.0201314509\n",
      "Epoch:14 \t train_loss:0.0176171752 \t valid_loss:0.0181756010\n",
      "Epoch:19 \t train_loss:0.0168729202 \t valid_loss:0.0177639565\n",
      "Epoch:24 \t train_loss:0.0156806026 \t valid_loss:0.0172905331\n",
      "Epoch:29 \t train_loss:0.0144620154 \t valid_loss:0.0171604658\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0184233453 \t valid_loss:0.0180859099\n",
      "Epoch:9 \t train_loss:0.0184679937 \t valid_loss:0.0179022503\n",
      "Epoch:14 \t train_loss:0.0171269765 \t valid_loss:0.0179405963\n",
      "Epoch:19 \t train_loss:0.0165745743 \t valid_loss:0.0176819663\n",
      "Epoch:24 \t train_loss:0.0151946774 \t valid_loss:0.0172808533\n",
      "Epoch:29 \t train_loss:0.0137868380 \t valid_loss:0.0171854315\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_3 \t Seed:50 \t oof_loss:0.0173412495\n",
      "Model:version_3 \t valid_loss:0.0171357658\n",
      "Training model:version_4\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0220951729 \t valid_loss:0.0204410111\n",
      "Epoch:9 \t train_loss:0.0182303913 \t valid_loss:0.0182563903\n",
      "Epoch:14 \t train_loss:0.0172808521 \t valid_loss:0.0181930382\n",
      "Epoch:19 \t train_loss:0.0166607735 \t valid_loss:0.0173659401\n",
      "Epoch:24 \t train_loss:0.0154416541 \t valid_loss:0.0170884258\n",
      "Epoch:29 \t train_loss:0.0140480011 \t valid_loss:0.0169713244\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0218566899 \t valid_loss:0.0209937195\n",
      "Epoch:9 \t train_loss:0.0175840881 \t valid_loss:0.0183110662\n",
      "Epoch:14 \t train_loss:0.0170849343 \t valid_loss:0.0181884801\n",
      "Epoch:19 \t train_loss:0.0165142249 \t valid_loss:0.0177731521\n",
      "Epoch:24 \t train_loss:0.0153017527 \t valid_loss:0.0176156004\n",
      "Epoch:29 \t train_loss:0.0140142642 \t valid_loss:0.0175441200\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0221690630 \t valid_loss:0.0206820856\n",
      "Epoch:9 \t train_loss:0.0181594001 \t valid_loss:0.0183176463\n",
      "Epoch:14 \t train_loss:0.0173678390 \t valid_loss:0.0194999254\n",
      "Epoch:19 \t train_loss:0.0165897155 \t valid_loss:0.0178218364\n",
      "Epoch:24 \t train_loss:0.0153691349 \t valid_loss:0.0174728615\n",
      "Epoch:29 \t train_loss:0.0141964653 \t valid_loss:0.0175104327\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0223040748 \t valid_loss:0.0211967480\n",
      "Epoch:9 \t train_loss:0.0182876033 \t valid_loss:0.0312737543\n",
      "Epoch:14 \t train_loss:0.0174980341 \t valid_loss:0.0182164771\n",
      "Epoch:19 \t train_loss:0.0167285069 \t valid_loss:0.0176331636\n",
      "Epoch:24 \t train_loss:0.0155943634 \t valid_loss:0.0171175423\n",
      "Epoch:29 \t train_loss:0.0143613996 \t valid_loss:0.0169955413\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0220181474 \t valid_loss:0.0204691675\n",
      "Epoch:9 \t train_loss:0.0178719682 \t valid_loss:0.0180631334\n",
      "Epoch:14 \t train_loss:0.0171890968 \t valid_loss:0.0178190896\n",
      "Epoch:19 \t train_loss:0.0167216222 \t valid_loss:0.0173689347\n",
      "Epoch:24 \t train_loss:0.0154097197 \t valid_loss:0.0170386391\n",
      "Epoch:29 \t train_loss:0.0141739729 \t valid_loss:0.0170656976\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_4 \t Seed:11 \t oof_loss:0.0171740871\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0223367217 \t valid_loss:0.0213284188\n",
      "Epoch:9 \t train_loss:0.0180246740 \t valid_loss:0.0180257917\n",
      "Epoch:14 \t train_loss:0.0173348432 \t valid_loss:0.0177657509\n",
      "Epoch:19 \t train_loss:0.0166430870 \t valid_loss:0.0172189226\n",
      "Epoch:24 \t train_loss:0.0154150162 \t valid_loss:0.0171846343\n",
      "Epoch:29 \t train_loss:0.0142020225 \t valid_loss:0.0171006431\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0220862801 \t valid_loss:0.0210385196\n",
      "Epoch:9 \t train_loss:0.0178141774 \t valid_loss:0.0183483406\n",
      "Epoch:14 \t train_loss:0.0171599523 \t valid_loss:0.0182878998\n",
      "Epoch:19 \t train_loss:0.0166110845 \t valid_loss:0.0180399734\n",
      "Epoch:24 \t train_loss:0.0154583577 \t valid_loss:0.0175621579\n",
      "Epoch:29 \t train_loss:0.0142550606 \t valid_loss:0.0175128177\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0219449898 \t valid_loss:0.0208271640\n",
      "Epoch:9 \t train_loss:0.0179279182 \t valid_loss:0.0183242232\n",
      "Epoch:14 \t train_loss:0.0172276981 \t valid_loss:0.0180393869\n",
      "Epoch:19 \t train_loss:0.0165978219 \t valid_loss:0.0176406328\n",
      "Epoch:24 \t train_loss:0.0154069347 \t valid_loss:0.0174871195\n",
      "Epoch:29 \t train_loss:0.0142164325 \t valid_loss:0.0174742317\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0221416008 \t valid_loss:0.0215996011\n",
      "Epoch:9 \t train_loss:0.0188756970 \t valid_loss:0.0185234207\n",
      "Epoch:14 \t train_loss:0.0174371701 \t valid_loss:0.0178438377\n",
      "Epoch:19 \t train_loss:0.0167480014 \t valid_loss:0.0173768823\n",
      "Epoch:24 \t train_loss:0.0156156109 \t valid_loss:0.0170491972\n",
      "Epoch:29 \t train_loss:0.0144207492 \t valid_loss:0.0170088750\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0223870010 \t valid_loss:0.0205349275\n",
      "Epoch:9 \t train_loss:0.0182352428 \t valid_loss:0.0183365351\n",
      "Epoch:14 \t train_loss:0.0173399437 \t valid_loss:0.0176878718\n",
      "Epoch:19 \t train_loss:0.0167136817 \t valid_loss:0.0173552130\n",
      "Epoch:24 \t train_loss:0.0154692888 \t valid_loss:0.0170295182\n",
      "Epoch:29 \t train_loss:0.0142373947 \t valid_loss:0.0170117997\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_4 \t Seed:221 \t oof_loss:0.0172040589\n",
      "Training fold: 0\n",
      "Epoch:4 \t train_loss:0.0221218115 \t valid_loss:0.0206313540\n",
      "Epoch:9 \t train_loss:0.0178852987 \t valid_loss:0.0185282161\n",
      "Epoch:14 \t train_loss:0.0173524512 \t valid_loss:0.0174366076\n",
      "Epoch:19 \t train_loss:0.0167149280 \t valid_loss:0.0173473910\n",
      "Epoch:24 \t train_loss:0.0155675936 \t valid_loss:0.0170214692\n",
      "Epoch:29 \t train_loss:0.0142528250 \t valid_loss:0.0170510202\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 1\n",
      "Epoch:4 \t train_loss:0.0226034024 \t valid_loss:0.0217016819\n",
      "Epoch:9 \t train_loss:0.0176349267 \t valid_loss:0.0183900856\n",
      "Epoch:14 \t train_loss:0.0171790155 \t valid_loss:0.0180839341\n",
      "Epoch:19 \t train_loss:0.0165476717 \t valid_loss:0.0178642889\n",
      "Epoch:24 \t train_loss:0.0154094699 \t valid_loss:0.0175250889\n",
      "Epoch:29 \t train_loss:0.0142013617 \t valid_loss:0.0174934927\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 2\n",
      "Epoch:4 \t train_loss:0.0220765292 \t valid_loss:0.0204296747\n",
      "Epoch:9 \t train_loss:0.0178578219 \t valid_loss:0.0191140554\n",
      "Epoch:14 \t train_loss:0.0172225113 \t valid_loss:0.0180728804\n",
      "Epoch:19 \t train_loss:0.0166343914 \t valid_loss:0.0176580471\n",
      "Epoch:24 \t train_loss:0.0154640012 \t valid_loss:0.0174742286\n",
      "Epoch:29 \t train_loss:0.0142709716 \t valid_loss:0.0173631808\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 3\n",
      "Epoch:4 \t train_loss:0.0218400077 \t valid_loss:0.0210725443\n",
      "Epoch:9 \t train_loss:0.0179570379 \t valid_loss:0.0198843240\n",
      "Epoch:14 \t train_loss:0.0173752606 \t valid_loss:0.0178201969\n",
      "Epoch:19 \t train_loss:0.0168807996 \t valid_loss:0.0173337086\n",
      "Epoch:24 \t train_loss:0.0154556052 \t valid_loss:0.0171823390\n",
      "Epoch:29 \t train_loss:0.0141761311 \t valid_loss:0.0170889131\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Training fold: 4\n",
      "Epoch:4 \t train_loss:0.0220674180 \t valid_loss:0.0214289910\n",
      "Epoch:9 \t train_loss:0.0180130672 \t valid_loss:0.0181024218\n",
      "Epoch:14 \t train_loss:0.0172748414 \t valid_loss:0.0178927343\n",
      "Epoch:19 \t train_loss:0.0166348322 \t valid_loss:0.0175161815\n",
      "Epoch:24 \t train_loss:0.0154767129 \t valid_loss:0.0170658594\n",
      "Epoch:29 \t train_loss:0.0141920603 \t valid_loss:0.0170670577\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Model:version_4 \t Seed:50 \t oof_loss:0.0171844924\n",
      "Model:version_4 \t valid_loss:0.0169953153\n"
     ]
    }
   ],
   "source": [
    "models_valid_predictions = []\n",
    "models_test_predictions = []\n",
    "\n",
    "seed_losses = []\n",
    "\n",
    "for model_train_config in models_train_configs:\n",
    "    print(f'Training model:{model_train_config.model_name}')\n",
    "    \n",
    "    single_model_valid_predictions = []\n",
    "    single_model_test_predictions = []\n",
    "    \n",
    "    for seed in SEEDS:\n",
    "        seed_everything(seed)\n",
    "\n",
    "        model_seed_valid_predictions = []\n",
    "        model_seed_test_predictions = []\n",
    "\n",
    "        for fold in range(FOLDS):\n",
    "            print(f'Training fold: {fold}')\n",
    "\n",
    "            fold_test_data = test_data[test_data.cp_type == 'trt_cp'].reset_index(drop=True)\n",
    "\n",
    "            train_loader, valid_loader, test_loader = preprocess_fold_data(train_data=train_data, \n",
    "                                                                           test_data=fold_test_data, \n",
    "                                                                           fold=fold, \n",
    "                                                                           scaling_func=model_train_config.scaling_func)\n",
    "            \n",
    "            number_of_genes, number_of_cells = train_loader.dataset.number_of_features()\n",
    "\n",
    "            model_config = ModelConfig(number_of_genes=number_of_genes, \n",
    "                                       number_of_cells=number_of_cells, \n",
    "                                       number_of_targets=len(target_columns))\n",
    "\n",
    "            model, best_model, optimizer, scheduler, loss_fn = model_train_config.factory_func(train_loader, EPOCHS)\n",
    "\n",
    "            best_model, valid_predictions, test_predictions = train_model(model=model,\n",
    "                                                                          best_model=best_model,\n",
    "                                                                          optimizer=optimizer, \n",
    "                                                                          scheduler=scheduler, \n",
    "                                                                          loss_fn=loss_fn, \n",
    "                                                                          train_loader=train_loader, \n",
    "                                                                          valid_loader=valid_loader, \n",
    "                                                                          test_loader=test_loader, \n",
    "                                                                          epochs=EPOCHS)\n",
    "\n",
    "            #TODO: Save the model here.\n",
    "            torch.save(best_model.state_dict(), f'model-{model_train_config.model_name}_fold-{fold}_seed-{seed}')\n",
    "            \n",
    "            model_seed_valid_predictions.append(valid_predictions)\n",
    "            model_seed_test_predictions.append(test_predictions)\n",
    "            print('-' * 100)\n",
    "\n",
    "\n",
    "        valid_predictions = pd.concat(model_seed_valid_predictions).reset_index(drop=True)\n",
    "        test_predictions = scale_predictions(model_seed_test_predictions, target_columns)\n",
    "        \n",
    "        single_model_valid_predictions.append(valid_predictions)\n",
    "        single_model_test_predictions.append(test_predictions)\n",
    "        \n",
    "        valid_loss, _ = calculate_log_loss(valid_predictions, train_data, target_columns)\n",
    "\n",
    "        seed_losses.append(valid_loss)\n",
    "\n",
    "        print(f'Model:{model_train_config.model_name} \\t Seed:{seed} \\t oof_loss:{valid_loss:.10f}')\n",
    "\n",
    "    valid_predictions = scale_predictions(single_model_valid_predictions, target_columns)\n",
    "    test_predictions = scale_predictions(single_model_test_predictions, target_columns)\n",
    "    \n",
    "    models_valid_predictions.append(valid_predictions)\n",
    "    models_test_predictions.append(test_predictions)\n",
    "    \n",
    "    valid_loss, _ = calculate_log_loss(valid_predictions, train_data, target_columns)\n",
    "\n",
    "    print(f'Model:{model_train_config.model_name} \\t valid_loss:{valid_loss:.10f}')\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:21:47.022592Z",
     "iopub.status.busy": "2020-12-29T15:21:47.021805Z",
     "iopub.status.idle": "2020-12-29T15:21:57.361282Z",
     "shell.execute_reply": "2020-12-29T15:21:57.360437Z"
    },
    "papermill": {
     "duration": 10.490385,
     "end_time": "2020-12-29T15:21:57.361389",
     "exception": false,
     "start_time": "2020-12-29T15:21:46.871004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal blend weights: [0.24941872 0.21155631 0.14350498 0.39551999]\n"
     ]
    }
   ],
   "source": [
    "#Finding optimal blend weights\n",
    "blend_weights = find_optimal_blend(models_valid_predictions, train_data, target_columns)\n",
    "\n",
    "print(f'Optimal blend weights: {blend_weights}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:21:57.658289Z",
     "iopub.status.busy": "2020-12-29T15:21:57.657048Z",
     "iopub.status.idle": "2020-12-29T15:22:00.050042Z",
     "shell.execute_reply": "2020-12-29T15:22:00.048614Z"
    },
    "papermill": {
     "duration": 2.542469,
     "end_time": "2020-12-29T15:22:00.050153",
     "exception": false,
     "start_time": "2020-12-29T15:21:57.507684",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "valid_predictions = scale_predictions(models_valid_predictions, target_columns, blend_weights)\n",
    "test_predictions = scale_predictions(models_test_predictions, target_columns, blend_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:22:00.346559Z",
     "iopub.status.busy": "2020-12-29T15:22:00.345299Z",
     "iopub.status.idle": "2020-12-29T15:22:01.273013Z",
     "shell.execute_reply": "2020-12-29T15:22:01.272544Z"
    },
    "papermill": {
     "duration": 1.078138,
     "end_time": "2020-12-29T15:22:01.273109",
     "exception": false,
     "start_time": "2020-12-29T15:22:00.194971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.016912176731223444\n"
     ]
    }
   ],
   "source": [
    "validation_loss, _ = calculate_log_loss(valid_predictions, train_data, target_columns)\n",
    "print(f'Validation loss: {validation_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:22:01.567487Z",
     "iopub.status.busy": "2020-12-29T15:22:01.566840Z",
     "iopub.status.idle": "2020-12-29T15:22:01.570208Z",
     "shell.execute_reply": "2020-12-29T15:22:01.570687Z"
    },
    "papermill": {
     "duration": 0.152522,
     "end_time": "2020-12-29T15:22:01.570798",
     "exception": false,
     "start_time": "2020-12-29T15:22:01.418276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed loss std: 0.0000571888\n"
     ]
    }
   ],
   "source": [
    "print(f'Seed loss std: {np.array(seed_losses).std():.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:22:01.882734Z",
     "iopub.status.busy": "2020-12-29T15:22:01.881900Z",
     "iopub.status.idle": "2020-12-29T15:22:01.894562Z",
     "shell.execute_reply": "2020-12-29T15:22:01.894095Z"
    },
    "papermill": {
     "duration": 0.168664,
     "end_time": "2020-12-29T15:22:01.894657",
     "exception": false,
     "start_time": "2020-12-29T15:22:01.725993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_ids = test_data[test_data.cp_type == 'ctl_vehicle'].sig_id.values\n",
    "\n",
    "zero_df = pd.DataFrame(np.zeros((len(zero_ids), len(target_columns))), columns=target_columns)\n",
    "zero_df['sig_id'] = zero_ids\n",
    "\n",
    "nonzero_df = test_predictions[~test_predictions.sig_id.isin(zero_ids)]\n",
    "nonzero_df = nonzero_df[target_columns + ['sig_id']].reset_index(drop=True)\n",
    "submission = pd.concat([nonzero_df, zero_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:22:02.190805Z",
     "iopub.status.busy": "2020-12-29T15:22:02.190287Z",
     "iopub.status.idle": "2020-12-29T15:22:04.337264Z",
     "shell.execute_reply": "2020-12-29T15:22:04.336782Z"
    },
    "papermill": {
     "duration": 2.297001,
     "end_time": "2020-12-29T15:22:04.337393",
     "exception": false,
     "start_time": "2020-12-29T15:22:02.040392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-29T15:22:04.827346Z",
     "iopub.status.busy": "2020-12-29T15:22:04.826542Z",
     "iopub.status.idle": "2020-12-29T15:22:04.840326Z",
     "shell.execute_reply": "2020-12-29T15:22:04.840714Z"
    },
    "papermill": {
     "duration": 0.356947,
     "end_time": "2020-12-29T15:22:04.840836",
     "exception": false,
     "start_time": "2020-12-29T15:22:04.483889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>adrenergic_receptor_agonist</th>\n",
       "      <th>...</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "      <th>sig_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.014007</td>\n",
       "      <td>0.020311</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.008374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001330</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000530</td>\n",
       "      <td>0.000940</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>id_0004d9e33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.015163</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.011257</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.014713</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.003129</td>\n",
       "      <td>id_001897cda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.015345</td>\n",
       "      <td>0.018921</td>\n",
       "      <td>0.004220</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.007766</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.008163</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.001906</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>id_00276f245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001435</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.024293</td>\n",
       "      <td>0.004680</td>\n",
       "      <td>0.003772</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.003238</td>\n",
       "      <td>0.001507</td>\n",
       "      <td>0.001197</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.001046</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001596</td>\n",
       "      <td>id_0027f1083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.001790</td>\n",
       "      <td>0.022545</td>\n",
       "      <td>0.025744</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.002675</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.010715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.002978</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.001410</td>\n",
       "      <td>id_006fc47b8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  acat_inhibitor  \\\n",
       "0                     0.000814                0.000792        0.002127   \n",
       "1                     0.000448                0.000667        0.001105   \n",
       "2                     0.000617                0.000714        0.001744   \n",
       "3                     0.001374                0.001135        0.001435   \n",
       "4                     0.000691                0.000689        0.001790   \n",
       "\n",
       "   acetylcholine_receptor_agonist  acetylcholine_receptor_antagonist  \\\n",
       "0                        0.014007                           0.020311   \n",
       "1                        0.002065                           0.001819   \n",
       "2                        0.015345                           0.018921   \n",
       "3                        0.016436                           0.024293   \n",
       "4                        0.022545                           0.025744   \n",
       "\n",
       "   acetylcholinesterase_inhibitor  adenosine_receptor_agonist  \\\n",
       "0                        0.004433                    0.002258   \n",
       "1                        0.001578                    0.004356   \n",
       "2                        0.004220                    0.002807   \n",
       "3                        0.004680                    0.003772   \n",
       "4                        0.004296                    0.003590   \n",
       "\n",
       "   adenosine_receptor_antagonist  adenylyl_cyclase_activator  \\\n",
       "0                       0.004669                    0.000236   \n",
       "1                       0.009554                    0.005368   \n",
       "2                       0.005043                    0.000266   \n",
       "3                       0.002728                    0.000357   \n",
       "4                       0.002675                    0.000276   \n",
       "\n",
       "   adrenergic_receptor_agonist  ...  trpv_agonist  trpv_antagonist  \\\n",
       "0                     0.008374  ...      0.001330         0.003498   \n",
       "1                     0.015163  ...      0.001039         0.002600   \n",
       "2                     0.007766  ...      0.001259         0.002291   \n",
       "3                     0.013833  ...      0.000648         0.003238   \n",
       "4                     0.010715  ...      0.001037         0.002978   \n",
       "\n",
       "   tubulin_inhibitor  tyrosine_kinase_inhibitor  \\\n",
       "0           0.001483                   0.000942   \n",
       "1           0.000562                   0.011257   \n",
       "2           0.008163                   0.005422   \n",
       "3           0.001507                   0.001197   \n",
       "4           0.004684                   0.001436   \n",
       "\n",
       "   ubiquitin_specific_protease_inhibitor  vegfr_inhibitor  vitamin_b  \\\n",
       "0                               0.000530         0.000940   0.001786   \n",
       "1                               0.000347         0.014713   0.000895   \n",
       "2                               0.000419         0.001800   0.001906   \n",
       "3                               0.000522         0.001046   0.001740   \n",
       "4                               0.000443         0.000775   0.002105   \n",
       "\n",
       "   vitamin_d_receptor_agonist  wnt_inhibitor        sig_id  \n",
       "0                    0.002402       0.001530  id_0004d9e33  \n",
       "1                    0.002473       0.003129  id_001897cda  \n",
       "2                    0.000966       0.001985  id_00276f245  \n",
       "3                    0.000500       0.001596  id_0027f1083  \n",
       "4                    0.000404       0.001410  id_006fc47b8  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 6064.759111,
   "end_time": "2020-12-29T15:22:06.398876",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-29T13:41:01.639765",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
